{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Late Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\el debs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models.loader import load_model\n",
    "from data.dataset import get_flair_loader, get_seg_loader, get_t2_loader, get_t1ce_loader, get_t1_loader\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn   \n",
    "import torchvision.transforms as T\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "number_patient = 200\n",
    "\n",
    "# Models class\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=256):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(32, momentum=0.9),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(64, momentum=0.9),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(128, momentum=0.9),\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(256, momentum=0.9),\n",
    "            nn.Conv2d(256, 256, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(256, momentum=0.9),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 3 * 4, self.latent_dim)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim, 256 * 3 * 4),\n",
    "            nn.Unflatten(1, (256, 3, 4)),\n",
    "            nn.ConvTranspose2d(self.latent_dim, 256, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(256, momentum=0.9),\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(128, momentum=0.9),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(64, momentum=0.9),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(32, momentum=0.9),\n",
    "            nn.ConvTranspose2d(32, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "    def train_reconstruction(self, loader, epochs=10, lr=0.001):\n",
    "        self.to(device)\n",
    "        self.train()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        for epoch in range(epochs):\n",
    "            for i, x in enumerate(loader):\n",
    "                x = x.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                x_reconstructed = self.forward(x)\n",
    "                loss = criterion(x_reconstructed, x)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if i % 100 == 0:\n",
    "                    print(f\"Epoch {epoch}, batch {i}/{len(loader)}, loss {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1050/1050 [00:12<00:00, 86.69it/s] \n",
      "100%|██████████| 1050/1050 [00:12<00:00, 86.41it/s]\n",
      "100%|██████████| 1050/1050 [00:12<00:00, 84.43it/s]\n",
      "100%|██████████| 1050/1050 [00:12<00:00, 83.88it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 79.22it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 85.90it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 81.48it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 80.49it/s]\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"t1\" : load_model(\"./models/t1.pth\"),\n",
    "    \"t1ce\" : load_model(\"./models/t1ce.pth\"),\n",
    "    \"flair\" : load_model(\"./models/flair.pth\"),\n",
    "    \"t2\" : load_model(\"./models/t2.pth\")\n",
    "}\n",
    "# All the dataset for each model\n",
    "data = {\n",
    "    \"t1\" : get_t1_loader(),\n",
    "    \"t1ce\" : get_t1ce_loader(),\n",
    "    \"flair\" : get_flair_loader(),\n",
    "    \"t2\" : get_t2_loader()\n",
    "}\n",
    "\n",
    "matrix = {}\n",
    "similarities = {}\n",
    "candidates = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_matrix_for (model_key):\n",
    "    \"\"\"\n",
    "    Return features matrix for each patient \n",
    "    \"\"\"\n",
    "\n",
    "    result = None\n",
    "    arrays = []\n",
    "\n",
    "    for index, batch in enumerate (data[model_key]) :\n",
    "        arrays.append(models[model_key].encode(batch))\n",
    "\n",
    "    result = torch.cat(tuple(arrays), dim=0)\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_similarity_matrix_for (model_key) :\n",
    "    \"\"\"\n",
    "    Return a similarity matrix for a specific model\n",
    "    \"\"\"\n",
    "\n",
    "    distance_matrix = np.zeros((number_patient, number_patient))\n",
    "    result = get_features_matrix_for(model_key)\n",
    "\n",
    "    for patient_1 in range (0, number_patient) :\n",
    "        for patient_2 in range (0, number_patient) :\n",
    "            distance_matrix[patient_1, patient_2] = torch.linalg.norm(result[patient_1] - result[patient_2], ord=2)\n",
    "        \n",
    "    return distance_matrix\n",
    "\n",
    "def get_most_similar_patient (key_model, similarity_matrix) :\n",
    "    \"\"\"\n",
    "    Sort patient index in order of most relevent to less relevent\n",
    "    \"\"\"\n",
    "\n",
    "    temp = np.zeros((number_patient, number_patient))\n",
    "\n",
    "    for candidate in range (number_patient) :\n",
    "        temp[candidate] = np.argsort(similarity_matrix[key_model][candidate])\n",
    "\n",
    "    return temp\n",
    "\n",
    "def get_sort_similar (key_model, similarity_matrix) :\n",
    "    \"\"\"\n",
    "    Sort patient values\n",
    "    \"\"\"\n",
    "\n",
    "    temp = np.zeros((number_patient, number_patient))\n",
    "\n",
    "    for candidate in range (number_patient) :\n",
    "        temp[candidate] = np.sort(similarity_matrix[key_model][candidate])\n",
    "\n",
    "    return temp\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting most similar patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data :\n",
    "    matrix[key] = get_features_matrix_for(key)\n",
    "    similarities[key]  = get_similarity_matrix_for (key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def borda_count (modals_keys) :\n",
    "    \"\"\"\n",
    "    Utilize borda_count to determine the candidates for \n",
    "    \"\"\"\n",
    "\n",
    "    temp_sim_indice = {}\n",
    "    temp_sim_sort = {}\n",
    "\n",
    "    end_most_relevant_candidate = np.zeros((number_patient, number_patient))\n",
    "    end_most_relevant_candidate_values = np.zeros((number_patient, number_patient))\n",
    "\n",
    "    for key in modals_keys :\n",
    "\n",
    "        temp_sim_indice [key] = get_most_similar_patient (key, similarities)\n",
    "        temp_sim_sort [key] = get_sort_similar (key, similarities)\n",
    "\n",
    "\n",
    "    # Getting the N ith patient in all models\n",
    "    for patient in range (number_patient) :\n",
    "\n",
    "        temp = {}\n",
    "        candidates_temp = {}\n",
    "\n",
    "        for key in modals_keys :\n",
    "            temp [key] = temp_sim_indice [key][patient]\n",
    "\n",
    "        for key in modals_keys :\n",
    "\n",
    "            # Counting ponderation\n",
    "\n",
    "            for i, candidate in enumerate( temp[key]) :\n",
    "                if candidate not in candidates_temp :\n",
    "                    candidates_temp[candidate] = number_patient - i\n",
    "                else :\n",
    "                    candidates_temp[candidate] += number_patient - i \n",
    "\n",
    "        sorted_list_patient = sorted (candidates_temp, key=candidates_temp.get)\n",
    "        sorted_list_patient.reverse()\n",
    "\n",
    "        value_sorted = sorted (candidates_temp.values())\n",
    "        value_sorted.reverse()\n",
    "\n",
    "        end_most_relevant_candidate[patient] = np.array(sorted_list_patient)\n",
    "        end_most_relevant_candidate_values[patient] = np.array(value_sorted)\n",
    "        # Borda count vote for the five models\n",
    "\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"candidates\" : end_most_relevant_candidate,\n",
    "        \"values_candidates\" : end_most_relevant_candidate_values\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_matrix = borda_count (data.keys())\n",
    "\n",
    "candidates_matrix['candidates'] = candidates_matrix['candidates'][:,1:]\n",
    "candidates_matrix['values_candidates']= candidates_matrix['values_candidates'][:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82245911, 0.8577357 , 0.86001779, 0.84384805, 0.8239485 ,\n",
       "        0.85025024, 0.84933212, 0.84582292, 0.82992151, 0.83515181,\n",
       "        0.84552729, 0.82532444, 0.82505279, 0.8401196 , 0.83646798,\n",
       "        0.8505333 , 0.86071333, 0.83575711, 0.83674904, 0.83906377,\n",
       "        0.84711791, 0.84435709, 0.82772311, 0.826835  , 0.86342462,\n",
       "        0.84718996, 0.84024042, 0.82002108, 0.82232115, 0.84775996,\n",
       "        0.82704775, 0.82707302, 0.85849851, 0.86810165, 0.84364039,\n",
       "        0.86066422, 0.85222457, 0.83879503, 0.84431929, 0.84270972,\n",
       "        0.83772172, 0.85594114, 0.83910083, 0.83538075, 0.85595874,\n",
       "        0.83633646, 0.84436767, 0.8666647 , 0.82471694, 0.8540424 ,\n",
       "        0.84227408, 0.8439962 , 0.86007306, 0.86854879, 0.83515426,\n",
       "        0.8585878 , 0.82614278, 0.83060612, 0.864261  , 0.86138798,\n",
       "        0.84850773, 0.84259706, 0.83970414, 0.87613908, 0.86706485,\n",
       "        0.85716744, 0.83735291, 0.84925946, 0.83133931, 0.85560747,\n",
       "        0.85127549, 0.8539983 , 0.85831997, 0.86167992, 0.85752657,\n",
       "        0.83474651, 0.85899738, 0.88009011, 0.87585039, 0.84971218,\n",
       "        0.8409753 , 0.86391096, 0.86146886, 0.86504977, 0.87273383,\n",
       "        0.84924995, 0.8578671 , 0.83536276, 0.85491326, 0.84795666,\n",
       "        0.86632731, 0.86156502, 0.86459129, 0.87397335, 0.88778101,\n",
       "        0.8564613 , 0.84977129, 0.87061909, 0.86469127, 0.87442849,\n",
       "        0.85882072, 0.87376057, 0.8524646 , 0.87953158, 0.85240203,\n",
       "        0.86342824, 0.86178892, 0.8627068 , 0.85060012, 0.8536293 ,\n",
       "        0.84354971, 0.85515703, 0.87971587, 0.88165256, 0.83467947,\n",
       "        0.86495959, 0.86908627, 0.87150396, 0.87430036, 0.86157697,\n",
       "        0.83183156, 0.87485495, 0.87054975, 0.85398335, 0.85720391,\n",
       "        0.87482256, 0.85854999, 0.87944074, 0.86984624, 0.84666704,\n",
       "        0.87404322, 0.8537826 , 0.89205918, 0.86537633, 0.87377605,\n",
       "        0.85096034, 0.83896371, 0.86136454, 0.87336023, 0.87878424,\n",
       "        0.85981308, 0.85349612, 0.87382994, 0.87530574, 0.8747373 ,\n",
       "        0.89400739, 0.89120567, 0.88765644, 0.89659029, 0.88722352,\n",
       "        0.88930132, 0.85893865, 0.88641836, 0.89500313, 0.86783791,\n",
       "        0.88797502, 0.87210285, 0.86852058, 0.8701    , 0.8877282 ,\n",
       "        0.85049633, 0.89414695, 0.88236982, 0.87498322, 0.87960291,\n",
       "        0.89162325, 0.8934462 , 0.8716979 , 0.86808823, 0.86441344,\n",
       "        0.89181158, 0.89674403, 0.87726217, 0.88183969, 0.87336915,\n",
       "        0.8883839 , 0.89766054, 0.8765977 , 0.89537516, 0.86815025,\n",
       "        0.89558951, 0.86817942, 0.90301902, 0.86169037, 0.88232505,\n",
       "        0.89092837, 0.88789716, 0.89285325, 0.87097951, 0.86751838,\n",
       "        0.86163095, 0.87522469, 0.89755876, 0.88856472, 0.87086584,\n",
       "        0.88622374, 0.88072665, 0.86212178, 0.8525077 , 0.86870151]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ground truth\n",
    "with open ('./data/IoU.pickle', \"rb\") as file :\n",
    "    djakkar =  pickle.load(file)\n",
    "\n",
    "djakkar_index = djakkar\n",
    "\n",
    "# Patient croissant matrix\n",
    "most_similar_patient_matrix = np.zeros(djakkar_index.shape)\n",
    "\n",
    "for x in range (most_similar_patient_matrix.shape[0]) :\n",
    "    most_similar_patient_matrix[x] = np.argsort(djakkar_index[x])\n",
    "\n",
    "\n",
    "most_similar_patient_matrix\n",
    "\n",
    "sorted_djakkar_index = np.zeros(djakkar_index.shape)\n",
    "\n",
    "for x in range (sorted_djakkar_index.shape[0]) :\n",
    "    sorted_djakkar_index[x] = np.sort(djakkar_index[x])\n",
    "\n",
    "\n",
    "sorted_djakkar_index\n",
    "\n",
    "testing_size = djakkar_index.shape[0]\n",
    "\n",
    "# Getting the NDCG score\n",
    "ndcg_matrix = np.zeros((1, testing_size))\n",
    "\n",
    "for x in range (testing_size) :\n",
    "    ndcg_matrix [0, x] = ndcg_score(np.asarray([most_similar_patient_matrix[:,1:][x]]), np.asarray([sorted_djakkar_index[:,1:][x]]))\n",
    "\n",
    "ndcg_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate models ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 1804.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.84042488 0.84671624 0.85082313 0.85261817 0.86495256 0.85363492\n",
      "  0.87147705 0.84385476 0.85947231 0.8717633  0.8491847  0.88872713\n",
      "  0.86551254 0.87177504 0.87033941 0.87086528 0.84797556 0.86754735\n",
      "  0.88159166 0.85356055 0.87451336 0.8570509  0.83746553 0.8710888\n",
      "  0.85309737 0.88635879 0.87514164 0.87403411 0.86569139 0.83111596\n",
      "  0.85656257 0.86104619 0.84053398 0.85783719 0.8762433  0.8827377\n",
      "  0.87050439 0.85477104 0.85287695 0.87732639 0.87015508 0.86117708\n",
      "  0.86600772 0.8849931  0.88012499 0.86107107 0.87214922 0.86424216\n",
      "  0.85660069 0.86423445 0.87761548 0.84836074 0.83752275 0.8656531\n",
      "  0.84726689 0.86602067 0.83606464 0.87641558 0.85866087 0.86719179\n",
      "  0.88254855 0.86130564 0.89866717 0.86882383 0.86161504 0.85775951\n",
      "  0.8798192  0.86986376 0.87956156 0.88050168 0.83441704 0.85814201\n",
      "  0.83979672 0.87568311 0.8713931  0.87414117 0.84453516 0.85938363\n",
      "  0.87164198 0.86699311 0.84829413 0.83938715 0.86025275 0.86605274\n",
      "  0.83796537 0.8628811  0.88965773 0.84493072 0.86478612 0.82852002\n",
      "  0.83537762 0.83961978 0.84399062 0.87596962 0.85551897 0.86432299\n",
      "  0.83434767 0.86042081 0.84245327 0.87724604 0.85980093 0.8577965\n",
      "  0.86293587 0.84645546 0.86087216 0.8525552  0.84038737 0.87084919\n",
      "  0.86132481 0.86011789 0.85442948 0.88146744 0.88619492 0.84952868\n",
      "  0.87088271 0.89353124 0.86136462 0.8698708  0.87757295 0.83328275\n",
      "  0.85909241 0.86275509 0.85244942 0.864152   0.85823475 0.8858258\n",
      "  0.86581577 0.85486035 0.87058331 0.84652592 0.83929045 0.86794216\n",
      "  0.85902277 0.87434549 0.81776624 0.8609821  0.89397781 0.88298037\n",
      "  0.85415306 0.85929532 0.84011062 0.86425272 0.84895085 0.86382858\n",
      "  0.84493206 0.86191001 0.84152332 0.85039637 0.84556416 0.88319067\n",
      "  0.84416129 0.86075126 0.87387021 0.84537655 0.87273144 0.88771652\n",
      "  0.84580992 0.85980802 0.86770222 0.83250576 0.85095292 0.87267589\n",
      "  0.855028   0.82606296 0.86965272 0.87826547 0.82090886 0.86947633\n",
      "  0.85106407 0.8660868  0.84657906 0.87549431 0.85146605 0.84129938\n",
      "  0.84830806 0.86330617 0.85056373 0.87760857 0.8580249  0.88594268\n",
      "  0.84960575 0.85313003 0.85405504 0.86107778 0.84570334 0.84163818\n",
      "  0.85982197 0.85656811 0.86816658 0.84220376 0.86812342 0.84386385\n",
      "  0.86395638 0.86709355 0.84790492 0.85313786 0.87229902 0.86705165\n",
      "  0.86124979 0.85333911]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ndcg_model_scores = np.zeros( (1, number_patient) )\n",
    "\n",
    "for patient in tqdm (range (number_patient)) :\n",
    "    ndcg_model_scores [0, patient] = ndcg_score([candidates_matrix[\"candidates\"][patient]], [candidates_matrix[\"values_candidates\"][patient]])\n",
    "\n",
    "print (ndcg_model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"./data/late_fusion_ndcg.pickle\", \"wb\") as file:\n",
    "    pickle.dump(ndcg_model_scores, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4c1b5ee30376b71eaa339265b8dea39d4cdab92fa92b725320d3eb2e4642e28"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
